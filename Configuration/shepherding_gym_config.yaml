# Configuration file
# In all scripts numpy is imported as np

seed: 1

Targets:
  N: 5
  state_dim: 4
  input_dim: 2
  # lim: ['inf', 'inf', 'inf', 'inf']

  initial_conditions:
    mode: random
    random:
      shape: circle
      circle:
        max_radius: 25

  parameters:
    mode: generate
    generate:
      D: 3
      damping: 3



Herders:
  N: 5
  state_dim: 2

  initial_conditions:
    mode: random
    random:
      shape: circle
      circle:
        max_radius: 25


RepulsionLongRange:
  p: 2
  parameters:
    mode: generate
    generate:
      strength: 15
      max_distance: 5

RepulsionShortRange:
  p: 4
  parameters:
    mode: generate
    generate:
      strength: 10
      max_distance: 1.5

AttractionLongRange:
  p: 2
  parameters:
    mode: generate
    generate:
      strength: 0   # -2 for cohesion
      max_distance: 10

TargetInteraction:
  p_attr: 2
  p_rep: 4
  is_attractive: False
  parameters:
    mode: generate
    generate:
      strength_attr: 4
      strength_rep: 10
      max_distance: 15



integrator:
  dt: 0.05

simulator:
  T: 10

environment:
  dimensions: [50, 50]
  goal_pos: [0, 0]
  goal_radius: 5
  final_goal_pos : [0, 0]
  num_steps : 2000
  start_step: 2000

renderer:
  activate: False
  background_color: 'white'
  agent_colors: ['magenta', 'blue']
  agent_shapes: ['circle', 'diamond']
  agent_sizes: [1, 1]
  render_mode: 'pygame'
  render_dt: 0.05

ShepherdingLogger:
  activate: 1
  comment_enable: 0
  log_name: Shepherding_Simulation
  log_path: ./logs
  print_freq_step: 0
  save_freq_step: 0
  print_freq_experiment: 1
  save_freq_experiment: 3

Gym:
  num_episodes : 5
  action_bound : 12
  reward_gain : 1
  num_acts: 5  # For DQN only

  single_agent_env:
    obs_style : "PPO"
    k_1 : 1
    k_2 : 1
    k_3 : 1
    k_4 : 1

  marl_wrapper:
    update_frequency    : 1
    num_closest_targets : 2
    num_closest_herders : 1
    low_level_policy    : "PPO"
    obs_style   : "DQN"

  # Network architecture configuration
  high_level_network:
    hidden_sizes: [ 256, 128 ]
    activation: "ReLU"

